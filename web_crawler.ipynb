{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ec16abc-89c7-4cbf-86d7-2d5e9dd9dfc2",
   "metadata": {},
   "source": [
    "### 1.\tCrawl dữ liệu từ các trang báo điện tử Việt Nam sử dụng BeautifulSoup và Requests.<br />Ví dụ thu thập tiêu đề, mô tả ngắn &rarr; làm dữ liệu cho bài toán phân lớp.\n",
    "- Import thư viện\n",
    "- BeautifulSoup là thư viện Python nhằm lấy dữ liệu từ file html, xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e22b803-b49a-4fc9-86be-ef264a63fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://vnexpress.net/khanh-thanh-khoi-cong-5-du-an-trong-diem-o-tp-hcm-4876018.html'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f5a9ea-9a97-4286-b021-3cd050698237",
   "metadata": {},
   "source": [
    "- Lấy file html của web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45fc09c5-7971-4b0d-8437-ed6e7469879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95769653-6e34-4025-986d-59ee3e1cc057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Khánh thành, khởi công 5 dự án trọng điểm ở TP HCM - Báo VnExpress'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93a516c-51c2-44b8-bbfa-c0c55823dce8",
   "metadata": {},
   "source": [
    "- class_ để không nhầm lẫn giữa các class của python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00d965e-9517-40fc-85c7-41dab82c333c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"description\">Nhà ga T3 Tân Sơn Nhất, đường kết nối và 20 km cao tốc Bến Lức - Long Thành được đưa vào khai thác; hai đoạn Vành đai 2 TP HCM được khởi công, sáng 19/4.</p>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p', class_='description')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d92da1b-7393-450e-91e1-00169da6ca62",
   "metadata": {},
   "source": [
    "### 2.\tThu thập dữ liệu từ các nguồn có sẵn (VNTC, UIT-VSFC, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77388659-9868-47c9-a0ad-3e9bbfa264f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from typing import List, Tuple, Dict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c50409b-8702-4399-ad4d-48401e4b4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full\"\n",
    "TEST_PATH = \"/Users/quytien/VNTC/Data/10Topics/Ver1.1/Test_Full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73adc796-961f-44e3-9120-95135ff84fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Van hoa': 0,\n",
       " 'The gioi': 1,\n",
       " 'Khoa hoc': 2,\n",
       " 'Suc khoe': 3,\n",
       " 'Chinh tri Xa hoi': 4,\n",
       " 'Vi tinh': 5,\n",
       " 'Kinh doanh': 6,\n",
       " 'The thao': 7,\n",
       " 'Phap luat': 8,\n",
       " 'Doi song': 9}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category2id = {category: idx for idx, category in enumerate(os.listdir(TRAIN_PATH))}\n",
    "category2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319ae61b-fe14-4a9f-a4b4-fa9a2a8c7a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Van hoa\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/The gioi\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Khoa hoc\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Suc khoe\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Chinh tri Xa hoi\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Vi tinh\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Kinh doanh\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/The thao\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Phap luat\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Doi song\n",
      "TEST:\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Van hoa\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/The gioi\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Khoa hoc\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Suc khoe\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Chinh tri Xa hoi\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Vi tinh\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Kinh doanh\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/The thao\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Phap luat\n",
      "/Users/quytien/VNTC/Data/10Topics/Ver1.1/Train_Full/Doi song\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "def read_file(category, file_name):\n",
    "    text_path = os.path.join(TRAIN_PATH, category, file_name)\n",
    "    with open(text_path, \"r\", encoding = 'utf-16') as file:\n",
    "        content = file.read()\n",
    "    return (content, category2id[category])\n",
    "print(\"TRAIN:\")\n",
    "for category in os.listdir(TRAIN_PATH):\n",
    "    category_path = os.path.join(TRAIN_PATH, category)\n",
    "    print(category_path)\n",
    "    data.extend([ read_file(category, file_name) for file_name in os.listdir(category_path)])\n",
    "test_data = []\n",
    "print(\"TEST:\")\n",
    "for category in os.listdir(TEST_PATH):\n",
    "    category_path = os.path.join(TRAIN_PATH, category)\n",
    "    print(category_path)\n",
    "    test_data.extend([ read_file(category, file_name) for file_name in os.listdir(category_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51887565-709f-40ec-810b-000985e513e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VNTCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "143270d3-b558-434c-bd3c-dafcd0cb0496",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_test_split(data, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d356a63-9e4e-465b-83aa-c4625d3b60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vntc_train_data = VNTCDataset(train_data)\n",
    "vntc_valid_data = VNTCDataset(valid_data)\n",
    "vntc_test_data = VNTCDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c6e21a-425c-4e26-ac9a-d4c080532916",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d5da7e-ea3f-416b-9781-1a3420f2a0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model max_length:  1000000000000000019884624838656\n"
     ]
    }
   ],
   "source": [
    "print(\"Model max_length: \", tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66cd5b46-fd22-4142-930c-cce7b6a07a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data: List[Tuple[str, int]]):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for content, label in data:\n",
    "        texts.append(content)\n",
    "        labels.append(label)    \n",
    "    input_ids = tokenizer.batch_encode_plus(texts, padding = True, truncation = True)['input_ids']\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    labels = torch.tensor(labels)\n",
    "    return input_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "080ba32f-6d6f-41e3-add5-046a06807c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset = vntc_train_data, batch_size = 32, collate_fn = collate_fn, shuffle = True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset = vntc_valid_data, batch_size = 32, collate_fn = collate_fn)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset = vntc_test_data, batch_size = 32, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52b83476-41cb-4662-986d-8172656758e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  1266,   175,  ...,     1,     1,     1],\n",
      "        [    0,  9916,  3230,  ...,     1,     1,     1],\n",
      "        [    0,   449,   585,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 61610, 12886,  ...,     1,     1,     1],\n",
      "        [    0,  1696, 21486,  ...,     1,     1,     1],\n",
      "        [    0,  3490, 33101,  ...,     1,     1,     1]]) tensor([9, 4, 4, 0, 6, 8, 0, 7, 1, 8, 2, 7, 1, 4, 5, 4, 7, 7, 4, 9, 9, 4, 4, 3,\n",
      "        2, 8, 7, 3, 7, 7, 3, 9])\n"
     ]
    }
   ],
   "source": [
    "for input_ids, labels in train_dataloader:\n",
    "    print(input_ids, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7852423d-fc24-4475-ae68-b8a465eee59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhobertForNewsClassification(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.phobert = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels = num_classes)\n",
    "        for param in self.phobert.roberta.parameters():\n",
    "            param.requires_grad = False\n",
    "    def forward(self, input_ids, labels):\n",
    "        out = self.phobert(input_ids, labels = labels)\n",
    "        probs = torch.softmax(out['logits'], dim = -1)\n",
    "        preds = torch.argmax(probs, dim = -1).cpu().detach().numpy()\n",
    "        out['preds'] = preds\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a1b61d-63bd-4309-9374-705203426d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = PhobertForNewsClassification(len(category2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9437b6a-dfd4-499f-9a8e-839c78cac9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_parameters(module: torch.nn.Module) -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "\n",
    "    Get the number of trainable, fixed and total parameters of a pytorch module.\n",
    "\n",
    "    :param module: pytorch module\n",
    "    :return: dict containing number of parameters\n",
    "    \"\"\"\n",
    "    trainable = 0\n",
    "    fixed = 0\n",
    "    for p in module.parameters():\n",
    "        if p.requires_grad:\n",
    "            trainable += p.numel()\n",
    "        else:\n",
    "            fixed += p.numel()\n",
    "    return {\"trainable\": trainable, \"fixed\": fixed, \"total\": trainable + fixed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "668278e8-68c6-40f0-aef1-1eac5779bcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trainable': 598282, 'fixed': 134407680, 'total': 135005962}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4611ec99-01d0-4946-aae3-0d48ffb57984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf7cebd9-e60b-4322-b053-c29a1fc4186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "EPOCH = 5\n",
    "LOG_STEP = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc1fa715-8adb-41c3-8462-8c9fa5e4c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr= LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "272a16c1-0e48-4d39-846f-30f6a0fc8af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader Step: 950\n",
      "Valid Loader Step: 106\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Loader Step: {len(train_dataloader)}\")\n",
    "print(f\"Valid Loader Step: {len(valid_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f254102f-e22b-4ee6-9f9c-fb244a450780",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d39edec0-e021-4245-b56d-09a530289c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (3221) must match the existing size (258) at non-singleton dimension 1.  Target sizes: [32, 3221].  Tensor sizes: [1, 258]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m input_ids = input_ids.to(device)\n\u001b[32m      8\u001b[39m labels = labels.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m loss = out[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     11\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mPhobertForNewsClassification.forward\u001b[39m\u001b[34m(self, input_ids, labels)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, labels):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mphobert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     probs = torch.softmax(out[\u001b[33m'\u001b[39m\u001b[33mlogits\u001b[39m\u001b[33m'\u001b[39m], dim = -\u001b[32m1\u001b[39m)\n\u001b[32m     10\u001b[39m     preds = torch.argmax(probs, dim = -\u001b[32m1\u001b[39m).cpu().detach().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:1322\u001b[39m, in \u001b[36mRobertaForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1314\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1315\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1316\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1317\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1318\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1319\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1320\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1333\u001b[39m sequence_output = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1334\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.classifier(sequence_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:909\u001b[39m, in \u001b[36mRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    907\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.embeddings, \u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    908\u001b[39m     buffered_token_type_ids = \u001b[38;5;28mself\u001b[39m.embeddings.token_type_ids[:, :seq_length]\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m     buffered_token_type_ids_expanded = \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    910\u001b[39m     token_type_ids = buffered_token_type_ids_expanded\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: The expanded size of the tensor (3221) must match the existing size (258) at non-singleton dimension 1.  Target sizes: [32, 3221].  Tensor sizes: [1, 258]"
     ]
    }
   ],
   "source": [
    "losses = 0\n",
    "for i in range(EPOCH):\n",
    "    print(f\"Epoch {i}:\")\n",
    "    model.train()\n",
    "    for step, (input_ids, labels) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(input_ids, labels)\n",
    "        loss = out['loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.detach().cpu().item()\n",
    "        if step % LOG_STEP == 0 and step > 0:\n",
    "            print(f\"Step {step}, Avg Loss {loss}\")\n",
    "            losses = 0\n",
    "    \n",
    "    preds = []\n",
    "    trues = []\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (input_ids, labels) in enumerate(valid_dataloader):\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            out = model(input_ids, labels)\n",
    "            loss = out['loss']\n",
    "            valid_loss += loss.detach().cpu().item()\n",
    "            preds.extend(out['preds'])\n",
    "            trues.extend(labels.detach().cpu().numpy())\n",
    "    print(classification_report(trues, preds, target_names = list(category2id.keys())))\n",
    "    print(f\"Valid loss: {valid_loss / len(valid_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c21ebca-2b7e-495b-8fb0-bb147d7d8257",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (2017) must match the existing size (258) at non-singleton dimension 1.  Target sizes: [32, 2017].  Tensor sizes: [1, 258]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m input_ids = input_ids.to(device)\n\u001b[32m      7\u001b[39m labels = labels.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m loss = out[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m preds.extend(out[\u001b[33m'\u001b[39m\u001b[33mpreds\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mPhobertForNewsClassification.forward\u001b[39m\u001b[34m(self, input_ids, labels)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, labels):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mphobert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     probs = torch.softmax(out[\u001b[33m'\u001b[39m\u001b[33mlogits\u001b[39m\u001b[33m'\u001b[39m], dim = -\u001b[32m1\u001b[39m)\n\u001b[32m     10\u001b[39m     preds = torch.argmax(probs, dim = -\u001b[32m1\u001b[39m).cpu().detach().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:1322\u001b[39m, in \u001b[36mRobertaForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1314\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1315\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1316\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1317\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1318\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1319\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1320\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1333\u001b[39m sequence_output = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1334\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.classifier(sequence_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:909\u001b[39m, in \u001b[36mRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    907\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.embeddings, \u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    908\u001b[39m     buffered_token_type_ids = \u001b[38;5;28mself\u001b[39m.embeddings.token_type_ids[:, :seq_length]\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m     buffered_token_type_ids_expanded = \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    910\u001b[39m     token_type_ids = buffered_token_type_ids_expanded\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: The expanded size of the tensor (2017) must match the existing size (258) at non-singleton dimension 1.  Target sizes: [32, 2017].  Tensor sizes: [1, 258]"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "trues = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for step, (input_ids, labels) in enumerate(test_dataloader):\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = model(input_ids, labels)\n",
    "        loss = out['loss']\n",
    "        preds.extend(out['preds'])\n",
    "        trues.extend(labels.detach().cpu().numpy())\n",
    "        \n",
    "print(classification_report(trues, preds, target_names = list(category2id.keys())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
